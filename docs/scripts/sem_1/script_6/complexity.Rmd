---
title: 'Знакомимся со сложностью алгоритмов'
output: 
  html_document:
    toc: TRUE
    toc_float: TRUE
    highlight: pygments
  # df_print: paged
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Зачем мы учим сортировки?

В 1 семестре вас заставляют писать несколько кодов, каждый из которых решает одну и ту же задачку (сортировка массива). Собственно, назревает вопрос: **а зачем нам учиться писать какие-то странные функции, которые мы никогда не будем использовать в жизни, более того, они ведь еще и задачку одну решают!?** Причины, на самом деле, 2! Рассмотрим каждую из них:

### Причина №1: алгоритмы сортировок как наука о решении любой задачи
Так получилось, что алгоритмы сортировок уж очень отличаются друг от друга; в каждом из этих алгоритмов используются разные способы решения задач, например, это конструкция `for внутри for`, `рекурсия`, `цикл while`, `вызов одной функции внутри другой`. Таким образом, изучив разные алгоритмы сортировок, вы научитесь использовать разные конструкции языков программирования, каждая из которых поможет вам в дальнейшем решить другие задачи, более направленные на вашу деятельность. 

### Причина №2: алгоритмы сортировок как изучение сложности
Изучая разные алгоритмы, решающую одну задачу, вы также можете научиться определять, какой алгоритм лучше! Понятие "лучше" уж очень ~~гуманитарно~~ абстрактно , поэтому информатики решили его формализировать. Вылилось это в что-то более конкретное, а именно в **сложности**. Сложность алгоритма позволяет определять, какой из алгоритмов более "хорошо" написан.  

Итак, изучая разные алгоритмы сортировок, вы также на конкретных примерах учитесь понимать, как писать код _проще_ (то есть с меньшей сложностью).

## Разнообразие сложностей и сложность по скорости
Сложность можно вычислять по-разному. Один из вариантом - это оценивать память, которую ваш алгоритм занимает на вашем устройстве, другой способ - определять _скорость_ работы алгоритма, то есть количество операций, которые ваш компьютер должен выполнить для решения задачи.  

Почему это важно? Важно это по одной простой причине: кол-во итераций, которое выполняет ваш компьютер, напрямую связано со временем выполнения вашего алгоритма. В программах, которые вы пишете на первом курсе, скорость выполнения вашим компьютером составляет менее секунды, вы ее даже не ощущаете, но такое, к сожалению, может быть не всегда. Бывают коды, которые перед тем как дать ответ, могут выполняться неделями! Возможно, некоторые из вас познакомятся с такими программами на 4-ом курсе.  

А сейчас пока можете подумать еще над способами вычисления _сложности_ алгоритма. Может в будущем ваш способ будет изучаться в университетах :)

**Замечание:** На данном курсе мы с вами остановимся только на сложности по скорости, которая тоже может быть разной.  

### Наглядный пример:  
Предположим у нас есть массив $(1, 0, 2, 3, 4, 5)$. Мы хотим отсортировать данный массив методом "пузырька", то есть сравнивая попарно каждые элементы в данном массиве, и если элемент справа меньше элемента слева, то мы их меняем местами. Вы уже писали данную программу, поэтому знаете, как такая функция устроена.

Итак, начнем менять элементы:

_На шаге №1_ мы берем 1 и 2 элементы (то есть 1 и 0). Мы видим, что 0 < 1, поэтому мы меняем их местами, после чего получаем массив $(0, 1, 2, 3, 4, 5)$, который уже является **отсортированным**!  

Итак, нам с вами понадобилась всего 1! раз пробежаться по массиву, чтобы его отсортировать, и это вроде звучит неплохо.

Теперь представим, что элементы в массиве расположены так: $(5, 4, 3, 2, 1, 0)$, и нам опять нужно отсортировать такой массив в порядке _возрастания_. Сколько в таком случае нам понадобится итераций? Подумайте над этим :)

### Сложности в хорошем и плохом случае:
На рассмотренном примере мы с вами выяснили, что _в зависимости от исходных данных один и тот же алгоритм может справляться с задачей с разной скоростью_. Умные информатики заметили это намного раньше нас и решили разделять сложность по скорости на разные категории, а именно:

1. Сложность в худшем случае (для "пузырька" в рассмотренном нами примере это массив$(5, 4, 3, 2, 1, 0)$)
2. Сложность в лучшем случае (для "пузырька" в рассмотренном нами примере это массив $(1, 0, 2, 3, 4, 5)$)
3. Сложность в среднем

**Замечание:** В данном курсе мы будем рассматривать только сложность _в худшем случае_, поэтому если вас просят в домашке посчитать сложность, подразумевается худший случай. 

### Какие значения может принимать сложность?
Из курса математического анализ известен ряд, который отражает скорость роста различных видов зависимостей. Вот он в отсортированном порядке (от медленной функции к быстрой):
$ $

```{r echo = FALSE}
library(ggplot2)
library(RColorBrewer)
n <- seq(1, 4.7, 0.01)
cl <- brewer.pal(n = 6,name = 'Set2')
df <- data.frame(n, y1 = log2(n), y2 = n*log2(n), y3 = n**2, y4 = 2**n, y5 = factorial(n))

ggplot(df, aes(x = n)) + 
  geom_line(aes(y = n, col = cl[1])) + 
  geom_line(aes(y = y1, col = cl[2])) + 
  geom_line(aes(y = y2, col = cl[3])) + 
  geom_line(aes(y = y3, col = cl[4])) +
  geom_line(aes(y = y4, col = cl[5])) +
  geom_line(aes(y = y5, col = cl[6])) +
  labs(x = 'Число итераций, n', y = 'Сложность', title = 'Сравнение сложностей алгоритма') + 
  scale_color_discrete(
      name = 'Сложности',
      breaks = cl,
      labels = c('O(n)', 'O(log2(n))', 'O(n*log2(n))', 'O(n^2)', 'O(2^n)', 'O(n!)'),
      guide = 'legend') 
```

Если до сих пор думаете, что компьютер не может выполнять программу слишком долго, то вот наглядный пример того, как размер данных влияет на скорость работы.

![](https://github.com/MidiukinM/R_for_RANEPA/blob/master/docs/_includes/table.png?raw=true)

### Принятое свойство
Обычно, при вычислении сложности принято округлять значение до наиболее значимого веса (наибольшего порядка) и игнорировать константы, то есть, например, считается, что:

1. $O(\frac{1}{2}n + 1) = O(n)$ - константы не учитываются
2. $O(n^2 + n) = O(n^2)$ - берем только наибольший порядок ($n^2$)
3. $O(\frac{1}{2}n^2 + n + 1) = O(n^2)$ - все вместе

**Важное замечание:** сложность алгоритма записывается в общем случае! То есть как функция от $n$.

## Переходим к практике
Давайте теперь на примере разных кодов научимся считать сложности сами!  

Перед этим стоит отметить, что мы будем обозначать нашу сложность через символ $O$, который называется О-большое. 

### Пример №1 

Есть код:

```{r}
m <- matrix(1:9, nrow = 3, byrow = TRUE)
print(m)
for (i in 1:nrow(m)){
  for (j in 1:ncol(m)){
    print(m[i,j])
  }
}
```

Задача: посчитать сложность алгоритма  

Решение:  

Итак, мы с вами знаем, что `for внутри for` означает, что для каждой переменной из первого `for` берется заданное кол-во переменных из второго `for`. В данном примере, для каждой переменной $i$ от 1 до `nrow(m)` будет браться переменная $j$ $ncol(m)$ раз. $nrow(m)$ -это число строк в матрице $m$ (в данном случае 3), а $ncol(m)$ - это число столбцов в матрице $m$ (в данном случае тоже 3, матрица квадратная).  

Если чуть-чуть подумать, можно определить, что совокупное число итераций в данной задаче равно $nrow(m) \cdot ncol(m)$ раз (или $3 \cdot 3 = 9$, или $n * n = n^2$). Соответственно, сложность нашей задачи $O(n^2)$.

### Пример №2 

Есть код:

```{r}
n <- 4
for (i in 1:n){
  for (j in 1:(n-1)){
  }
}
```

Задача: вычислить сложность 

Решение:  

В первом цикле $n$ итераций, во вложенном втором цикле - $(n-1)$. Следовательно наша сложность: $O(n \cdot (n-1)) = O(n^2 - n) = O(n^2)$. 

**Важное замечание:** если в домашке вы округляете сложность алгоритма, пишите полностью вывод!

### Пример №3. Откуда в сложности берется логарифм?

Есть код:

```{r}
x <- 10
for (i in 1:4){
   x <- x / 2  
   print(x)
} 
```
Код очень простой, он делит $x$ на 2 четыре раза. Функция `print(x)` позволяет нам это явно увидеть. 

Итак, мы делим $x$ на 2 четыре раза, следовательно число наших операций = 4. Если мы посмотрим на эту задачку с конца, то можем заметить, что $x = 2^4 $, что довольно логично. 

Код №2:

```{r}
x <- 10
while (x > 0) {  
   x <- x / 2  
}
```

Этот код тоже очень простой. Цикл `while` говорит нам делить $x$ на 2, _пока_ выполняется условие $x > 0$.  

Однако здесь уже число итераций посчитать довольно сложно, ведь мы не знаем сколько раз надо разделить число 10 на 2, чтобы получить 0. Да и разве получим мы его вообще? Скорее только очень-очень близкое к нулю число.  

Итак, для того чтобы вычислить число операций алгоритма, а следовательно и сложность, нужно вспомнить определение _логарифма по степени 2_. Здесь вы должны помнить, что $log_216 = 4$, так как $2^4 = 16$.  

Ранее, мы определили, что $2^k = x$, где $k -$ число итераций. Ну тогда, используя определение логарифма: $k = log_2(x)$. Следовательно, наша сложность $O(log_2x)$.  

Если кто-то хочет побольше почитать про сложность $O(log_2n)$, то бегом [читать сюда про задачу бинарного поиска](https://ru.wikipedia.org/wiki/Двоичный_поиск).

## Краткий гайд по сложностям сортировок 

![](https://github.com/MidiukinM/R_for_RANEPA/blob/master/docs/_includes/complexity.png?raw=true)


